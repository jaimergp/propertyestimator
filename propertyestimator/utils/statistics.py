"""
A collection of classes for loading and manipulating statistics data files.
"""

import math
from enum import Enum
from io import StringIO

import numpy as np
import pandas as pd
from simtk import unit

from .utils import get_unitless_array


class AvailableQuantities(Enum):
    """The supported statistics which may be extracted / stored
    in statistics data files.
    """

    PotentialEnergy = 'PotentialEnergy'
    KineticEnergy = 'KineticEnergy'
    TotalEnergy = 'TotalEnergy'
    Temperature = 'Temperature'
    Volume = 'Volume'
    Density = 'Density'
    Enthalpy = 'Enthalpy'


class Statistics:
    """
    A data object for storing and retrieving statistics generated by an OpenMM simulation.
    """

    def __init__(self, potential_energies, kinetic_energies, total_energies,
                 temperatures, volumes, densities, enthalpies):
        """Constructs a new Statistics object.

        Parameters
        ----------
        """

        self._internal_data = {
            AvailableQuantities.PotentialEnergy: potential_energies,
            AvailableQuantities.KineticEnergy: kinetic_energies,
            AvailableQuantities.TotalEnergy: total_energies,
            AvailableQuantities.Temperature: temperatures,
            AvailableQuantities.Volume: volumes,
            AvailableQuantities.Density: densities,
            AvailableQuantities.Enthalpy: enthalpies,
        }

    def get_statistics(self, statistic_type):
        """Return the data for a given statistic.

        Parameters
        ----------
        statistic_type: Statistics.AvailableQuantities
            The type of statistic to retrieve.

        Returns
        -------
        Quantity[List]
            The data.
        """

        return self._internal_data[statistic_type]

    @classmethod
    def from_openmm_csv(cls, file_path, pressure=None):

        file_contents = None

        with open(file_path, 'r') as file:

            file_contents = file.read()

            if len(file_contents) < 1:
                raise ValueError('The statistics file is empty.')

            file_contents = file_contents[1:]

        string_object = StringIO(file_contents)
        data = pd.read_csv(string_object)

        if 'Potential Energy (kJ/mole)' not in data:
            raise ValueError('The statistics file does not contain a Potential Energy column.')

        potential_energies = list(data['Potential Energy (kJ/mole)']) * unit.kilojoule / unit.mole

        if 'Kinetic Energy (kJ/mole)' not in data:
            raise ValueError('The statistics file does not contain a Kinetic Energy column.')

        kinetic_energies = list(data['Kinetic Energy (kJ/mole)']) * unit.kilojoule / unit.mole

        if 'Total Energy (kJ/mole)' not in data:
            raise ValueError('The statistics file does not contain a Total Energy column.')

        total_energies = list(data['Total Energy (kJ/mole)']) * unit.kilojoule / unit.mole

        if 'Temperature (K)' not in data:
            raise ValueError('The statistics file does not contain a Temperature column.')

        temperatures = list(data['Temperature (K)']) * unit.kelvin

        if 'Box Volume (nm^3)' not in data:
            raise ValueError('The statistics file does not contain a Box Volume column.')

        volumes = list(data['Box Volume (nm^3)']) * unit.nanometer * unit.nanometer * unit.nanometer

        if 'Density (g/mL)' not in data:
            raise ValueError('The statistics file does not contain a Density column.')

        densities = list(data['Density (g/mL)']) * unit.gram / unit.milliliter

        enthalpies = None

        if pressure is not None:

            enthalpies = []

            for total_energy, volume in zip(total_energies, volumes):

                enthalpies.append((total_energy + volume * pressure *
                                   unit.AVOGADRO_CONSTANT_NA) / unit.kilojoule_per_mole)

            enthalpies *= unit.kilojoule_per_mole

        return cls(potential_energies, kinetic_energies, total_energies,
                   temperatures, volumes, densities, enthalpies)

    @classmethod
    def from_pandas_csv(cls, file_path):

        file_contents = None

        with open(file_path, 'r') as file:

            file_contents = file.read()

            if len(file_contents) < 1:
                raise ValueError('The statistics file is empty.')

        string_object = StringIO(file_contents)
        data = pd.read_csv(string_object)

        if 'Potential Energy (kJ/mole)' not in data:
            raise ValueError('The statistics file does not contain a Potential Energy column.')

        potential_energies = list(data['Potential Energy (kJ/mole)']) * unit.kilojoule / unit.mole

        if 'Kinetic Energy (kJ/mole)' not in data:
            raise ValueError('The statistics file does not contain a Kinetic Energy column.')

        kinetic_energies = list(data['Kinetic Energy (kJ/mole)']) * unit.kilojoule / unit.mole

        if 'Total Energy (kJ/mole)' not in data:
            raise ValueError('The statistics file does not contain a Total Energy column.')

        total_energies = list(data['Total Energy (kJ/mole)']) * unit.kilojoule / unit.mole

        if 'Temperature (K)' not in data:
            raise ValueError('The statistics file does not contain a Temperature column.')

        temperatures = list(data['Temperature (K)']) * unit.kelvin

        if 'Box Volume (nm^3)' not in data:
            raise ValueError('The statistics file does not contain a Box Volume column.')

        volumes = list(data['Box Volume (nm^3)']) * unit.nanometer * unit.nanometer * unit.nanometer

        if 'Density (g/mL)' not in data:
            raise ValueError('The statistics file does not contain a Density column.')

        densities = list(data['Density (g/mL)']) * unit.gram / unit.milliliter

        enthalpies = None

        if 'Enthalpy (kJ/mole)' in data:
            enthalpies = list(data['Enthalpy (kJ/mole)']) * unit.kilojoule_per_mole

        return cls(potential_energies, kinetic_energies, total_energies,
                   temperatures, volumes, densities, enthalpies)

    def save_as_pandas_csv(self, file_path):

        data = np.array([
            self._internal_data[AvailableQuantities.PotentialEnergy] / unit.kilojoule_per_mole,
            self._internal_data[AvailableQuantities.KineticEnergy] / unit.kilojoule_per_mole,
            self._internal_data[AvailableQuantities.TotalEnergy] / unit.kilojoule_per_mole,
            self._internal_data[AvailableQuantities.Temperature] / unit.kelvin,
            self._internal_data[AvailableQuantities.Volume] / unit.nanometer**3,
            self._internal_data[AvailableQuantities.Density] / unit.gram * unit.milliliter,
            self._internal_data[AvailableQuantities.Enthalpy] / unit.kilojoule_per_mole])

        data = data.transpose()

        columns = [
            "Potential Energy (kJ/mole)",
            "Kinetic Energy (kJ/mole)",
            "Total Energy (kJ/mole)",
            "Temperature (K)",
            "Box Volume (nm^3)",
            "Density (g/mL)",
            "Enthalpy (kJ/mole)"
        ]

        data_frame = pd.DataFrame(data=data, columns=columns)
        data_frame.to_csv(file_path)


def perform_bootstrapping(bootstrap_function, relative_sample_size, iterations, *data_sets):

    """Performs bootstrapping on a data set to calculate the
    average value, and the standard error in the average,
    bootstrapping.

    Parameters
    ----------
    bootstrap_function: function
        The function to apply to the bootstrapped data
    relative_sample_size: float
        The relative size of the data set to bootstrap on (i.e
        `sample size = data_set_size * relative_sample_size`).
    iterations: int
        The number of bootstrap iterations to perform.
    data_sets: np.ndarray of unit.Quantity
        The data sets to sample bootstrap. The data sets
        passed in must have the same number of samples.

    Returns
    -------
    np.ndarray of unit.Quantity
        The bootstrapped data.
    """

    assert len(data_sets) > 0

    # Make a copy of the data so we don't accidentally destroy anything.
    data_to_bootstrap = []

    data_set_size = len(data_sets[0])
    data_set_unit = None

    for data_set in data_sets:

        assert data_set_size == len(data_set)

        unitless_array, stripped_unit = get_unitless_array(data_set)

        if data_set_unit is not None:
            assert data_set_unit == stripped_unit

        data_set_unit = stripped_unit
        data_to_bootstrap.append(unitless_array)

    # Choose the sample size as a percentage of the full data set.
    sample_size = min(math.floor(data_set_size * relative_sample_size), data_set_size)

    evaluated_values = np.zeros(iterations)

    for bootstrap_iteration in range(iterations):

        sample_datasets = []

        for data_set in data_to_bootstrap:

            sample_indices = np.random.choice(data_set_size, sample_size)
            sample_datasets.append(data_set[sample_indices])

        evaluated_values[bootstrap_iteration] = bootstrap_function(*sample_datasets)

    return evaluated_values * data_set_unit
